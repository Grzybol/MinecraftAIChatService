services:
  aichatplayers:
    build: .
    image: minecraft-ai-chat-service
    ports:
      - "8090:8090"
    environment:
      LLM_SERVER_URL: http://llama-server:8080
    depends_on:
      - llama-server

  llama-server:
    image: ghcr.io/ggerganov/llama.cpp:server
    environment:
      LLAMA_ARG_MODEL: /models/model.gguf
      LLAMA_ARG_HOST: 0.0.0.0
      LLAMA_ARG_PORT: 8080
    ports:
      - "8080:8080"
    volumes:
      - ./models:/models:ro
