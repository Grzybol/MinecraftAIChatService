# Local model files

Store GGUF model files for the local `llama.cpp` runner in this directory, for example:

```
models/deepseek-1b.gguf
```

The service does **not** download models automatically. Set `LLM_MODEL_PATH` to point at the file you place here (or elsewhere on disk).
